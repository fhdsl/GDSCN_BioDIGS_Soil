[["index.html", "BioDIGS: Exploring Soil Data About this Book 0.1 Target Audience 0.2 Platform 0.3 Data", " BioDIGS: Exploring Soil Data February 24, 2025 About this Book This is a companion training guide for BioDIGS, a GDSCN project that brings a research experience into the classroom. This activity guides students through exploration of the BioDIGS soil data using the tidyverse in R. Students will learn basic data summarization, visualization, and mapping skills. Visit the BioDIGS (BioDiversity and Informatics for Genomics Scholars) website here for more information about this collaborative, distributed research project, including how you can get involved! The GDSCN (Genomics Data Science Community Network) is a consortium of educators who aim to create a world where researchers, educators, and students from diverse backgrounds are able to fully participate in genomic data science research. You can find more information about its mission and initiatives here. 0.1 Target Audience The activities in this guide are written for undergraduate students and beginning graduate students. Some sections require basic understanding of the R programming language, which is indicated at the beginning of the chapter. 0.2 Platform The activities in this guide are demonstrated on NHGRI’s AnVIL cloud computing platform. AnVIL is the preferred computing platform for the GDSCN. However, all of these activities can be done using your personal installation of R or using the online Galaxy portal. 0.3 Data The data generated by the BioDIGS project is available through the BioDIGS website, as well as through an AnVIL workspace. Data about the soil itself as well as soil metal content was generated by the Delaware Soil Testing Program at the University of Delaware. Sequences were generated by the Johns Hopkins University Genetic Resources Core Facility and by PacBio. "],["background.html", "Chapter 1 Background 1.1 What is genomics? 1.2 What is data science? 1.3 What is cloud computing? 1.4 Why soil microbes? 1.5 Heavy metals and human health", " Chapter 1 Background One critical aspect of an undergraduate STEM education is hands-on research. Undergraduate research experiences enhance what students learn in the classroom as well as increase a student’s interest in pursuing STEM careers (Russell, Hancock, and McCullough 2007). It can also lead to improved scientific reasoning and increased academic performance overall (Buffalari et al. 2020). However, many students at underresourced institutions like community colleges, Historically Black Colleges and Universities (HBCUs), tribal colleges and universities, and Hispanic-serving institutions have limited access to research opportunities compared to their cohorts at larger four-year colleges and R1 institutions. These students are also more likely to belong to groups that are already under-represented in STEM disciplines, particularly genomics and data science (Canner et al. 2017; GDSCN 2022). The BioDIGS Project aims to be at the intersection of genomics, data science, cloud computing, and education. 1.1 What is genomics? Genomics broadly refers to the study of genomes, which are an organism’s complete set of DNA. This includes both genes and non-coding regions of DNA. Traditional genomics involves sequencing and analyzing the genome of individual species. Metagenomics expands genomics to look at the collective genomes of entire communities of organisms in an environmental sample, like soil. It allows researchers to study not just the genes of culturable or isolated organisms, but the entirety of genetic material present in a given environment. By using genomic techniques to survey the soil microbes, we can identify everything in the soil, including microbes that no one has identified before. We are doing both traditional genomics and metagenomics as part of BioDIGS. 1.2 What is data science? Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data. It includes collecting, cleaning, and combining data from multiple databases, exploring data and developing statistical and machine learning models to identify patterns in complex datasets, and creating tools to efficiently store, process, and access large amounts of data. 1.3 What is cloud computing? Cloud computing just means using the internet to get access to powerful computer resources like storage, servers, databases, networking tools, and specialized software programs. Instead of having to buy and maintain their own powerful computers, storage servers, and other systems, users can pay to use them through an internet connection as needed. Users only pay for what they need, when they actually use it, and professionals update and maintain the systems in large data centers. It is a particularly useful tool for researchers and students at smaller institutions with limited computational services, especially when working with complex databases. The genome assembly and analyses for BioDIGS have been done using the NHGRI AnVIL cloud computing platform, as well as Galaxy. 1.4 Why soil microbes? It can be challenging to include undergraduates in human genomic and health research, especially in a classroom context. Both human genetic data and human health data are protected data, which limits the sort of information students can access without undergoing specialized ethics training. However, the same sorts of data cleaning and analysis methods used for human genomic data are also used for microbial genomic data, which does not have the same sort of legal protections as human genetic data. This makes it ideal for training undergraduate students at the beginning of their careers and can be used to prepare students for future research in human genomics and health (Jurkowski, Reid, and Labov 2017). Additionally, the microbes in the soil can have big impacts on our health (Brevik and Burgess 2014). 1.5 Heavy metals and human health Human activities that change the landscape can also change what sorts of inorganic and abiotic compounds we find in the soil, particularly increasing the amount of heavy metals (Yan et al. 2020). When cars drive on roads, compounds from the exhaust, oil, and other fluids might settle onto the roads and be washed into the soil. When we put salt on roads, parking lots, and sidewalks, the salts themselves will eventually be washed away and enter the ecosystem through both water and soil. Chemicals from factories and other businesses also leech into our environment. Previous research has demonstrated that in areas with more human activity, like cities, soils include greater concentrations of heavy metals than found in rural areas with limited human populations (Khan et al. 2023; Wang, Birch, and Liu 2022). Increased heavy metal concentrations also disproportionately affect lower-income and predominantly minority areas (Jones et al. 2022). Research suggests that increased heavy metal concentration in soils has major impacts on the soil microbial community. In particular, increased heavy metal concentration is associated with an increase in soil bacteria that have antibiotic resistance markers (Gorovtsov, Sazykin, and Sazykina 2018; Nguyen et al. 2019; Sun, Xu, and Fan 2021). References "],["research-team.html", "Chapter 2 Research Team 2.1 Soil sampling", " Chapter 2 Research Team This project is coordinated by the Genomics Data Science Community Network (GDSCN). You can read more about the GDSCN and its mission at the network website. 2.1 Soil sampling This map shows the current sampling locations for the BioDIGS project. The extensive network of the GDSCN has made this data collection possible. Soil sampling for this project was done by both faculty and student volunteers from schools that aren’t traditional R1 research institutions. Many of the faculty are also members of the GDSCN. This list of locations reflects GDSCN institutions and friends of GDSCN who have collected soil samples. Annandale, VA: Northern Virginia Community College Atlanta, GA: Spelman College Baltimore, MD: College of Southern Maryland, Notre Dame College of Maryland, Towson University Bismark, ND: United Tribes Technical College El Paso, TX: El Paso Community College, The University of Texas at El Paso Fresno, CA: Clovis Community College Greensboro, NC: North Carolina A&amp;T State University Harrisonburg, VA: James Madison University Honolulu, Hawai’i: University of Hawai’i at Mānoa Las Cruces, NM: Doña Ana Community College Montgomery County, MD: Montgomery College, Towson University Nashville, TN: Meharry Medical College New York, NY: Guttman Community College CUNY Petersburg, VA: Virginia State University Seattle, WA: North Seattle College, Pierce College Tsaile, AZ: Diné College "],["support.html", "Chapter 3 Support 3.1 Funding 3.2 Sponsors 3.3 Analytical and Computational Support", " Chapter 3 Support This project would not be possible without financial and technical support from many organizations and people. 3.1 Funding Funding for this project has been provided by the National Human Genome Research Institute (Contract # 75N92022P00232 awarded to Johns Hopkins University). 3.2 Sponsors PacBio and CosmosID have graciously donated supplies. Advances in Genome Biology and Technology provided funding support for several team members to attend AGBT 2024. 3.3 Analytical and Computational Support Computational support has been provided by NHGRI’s AnVIL cloud computing platform and Galaxy. "],["biodigs-data.html", "Chapter 4 BioDIGS Data 4.1 Sample Metadata 4.2 Soil Property Data 4.3 Genomics and Metagenomics Data and Metadata 4.4 BioDIGSData R package", " Chapter 4 BioDIGS Data There are currently three major kinds of data available from BioDIGS: sample metadata, soil testing data, and genomics and metagenomics data. All of these are available for use in your classroom. 4.1 Sample Metadata This dataset contains information about the samples themselves, including GPS coordinates for the sample location, date the sample was taken, and the site name. This dataset is also available from the BioDIGS website You can also see images of each sampling site and soil characteristics at the sample map. 4.2 Soil Property Data This dataset includes basic information about the soil itself like pH, percentage of organic matter, variety of soil metal concentrations. The complete data dictionary is available here. The dataset is available at the BioDIGS website. This dataset was generated by the Delaware Soil Testing Program at the University of Delaware. 4.3 Genomics and Metagenomics Data and Metadata In the future, you will be able to access this data in both raw and processed forms. The Illumina and Nanopore sequences were generated at the Johns Hopkins University Genetic Resources Core Facility. PacBio sequencing was done by PacBio directly. More information coming soon! 4.4 BioDIGSData R package We’ve created a data package to help you easily bring BioDIGS soil data and metadata into R! This package is currently in development, so if there’s a feature you’d like to see, please let us know! The most up-to-date version of the package can be accessed via GitHub at https://github.com/fhdsl/BioDIGSData 4.4.1 Installation Install the package by running the following in R. You might need to install the devtools package. devtools::install_github(&quot;fhdsl/BioDIGSData&quot;) 4.4.2 Usage Bring in the data using predefined functions. For example: # Load soil property data my_data &lt;- BioDIGSData::BioDIGS_soil_data() # Load site metadata my_data &lt;- BioDIGSData::BioDIGS_metadata() # Load DNA metadata my_data &lt;- BioDIGSData::BioDIGS_DNA_conc_data() "],["notes-about-the-activity.html", "Chapter 5 Notes about the Activity", " Chapter 5 Notes about the Activity Coming soon! "],["additional-lecture-material.html", "Chapter 6 Additional Lecture Material", " Chapter 6 Additional Lecture Material Coming soon! "],["using-anvil.html", "Chapter 7 Using AnVIL", " Chapter 7 Using AnVIL This activity was designed to work on local installations of RStudio, Posit cloud, or using NHGRI’s cloud computing platform AnVIL. If you’d like to get started with using AnVIL in the classroom, checkout the AnVIL Instructor’s Guide. This guide includes information on setting up billing, using premade content (or developing your own), and managing costs. There are also details guides on exploring and using AnVIL for students. "],["download.html", "Chapter 8 Download", " Chapter 8 Download Coming soon! "],["introduction.html", "Chapter 9 Introduction 9.1 Before You Start 9.2 Objectives", " Chapter 9 Introduction In this activity, you’ll have a chance to become familiar with the BioDIGS soil testing data. This dataset includes information on the inorganic components of each soil sample, particularly metal concentrations. Human activity can increase the concentration of inorganic compounds in the soil. When cars drive on roads, compounds from the exhaust, oil, and other fluids might settle onto the roads and be washed into the soil. When we put salt on roads, parking lots, and sidewalks, the salts themselves will eventually be washed away and enter the ecosystem through both water and soil. Chemicals from factories and other businesses also leech into our environment. All of this means the concentration of heavy metals and other chemicals will vary among the soil samples collected for the BioDIGS project. 9.1 Before You Start This activity requires RStudio. Make sure you have access to a working version of this software. 9.2 Objectives This activity will teach you how to use the AnVIL platform to: Open data from an R package Examine objects in R Calculate summary statistics for variables in the soil testing data Create and interpret histograms and boxplots for variables in the soil testing data "],["part-1.-examining-the-data.html", "Chapter 10 Part 1. Examining the Data", " Chapter 10 Part 1. Examining the Data We will use the BioDIGSData package to retrieve the data. We first need to install the package from where it is stored on GitHub. Packages and libraries You might see or hear the term “package” or “library” when working with the R programming language. Packages are collections of R functions, data, and documentation that extend the base functionality of R. They are the fundamental units of shareable code in R. Packages are developed by the R community and made available through repositories like CRAN (Comprehensive R Archive Network), Bioconductor, and GitHub. When you install a package, you gain access to all the functions, data, and documentation provided by that package. Libraries are the directories where packages are stored. We also use the library command to load and attach packages to the R environment. When you load a package using library(package_name), you make the functions and objects from a package available for use in your current R session. You may first need to install the remotes package to your RStudio environment. remotes is a package (or chunk of pre-written code) that allows you to download code that has been stored on GitHub into RStudio. install.packages(&quot;remotes&quot;) remotes::install_github(&quot;fhdsl/BioDIGSData&quot;, upgrade = &quot;never&quot;) If you’re having trouble with the code above, you can also try: install.packages(&quot;remotes&quot;) remotes::install_url(&#39;https://github.com/fhdsl/BioDIGSData/archive/refs/tags/v1.0.0.0.tar.gz&#39;) Once you’ve installed the package, we can load the package (which just means we have access to all the data stored in the BioDIGSData package). Then we assign the soil testing data to an object. This command follows the code structure: dataset_object_name &lt;- stored_BioDIGS_dataset The “dataset_object_name” is what RStudio will call the dataset after you open it. The “stored_BioDIGS_dataset” is what the dataset is called within the BioDIGSData package. Finally, the arrow (“&lt;-”) tells R to open the “stored_BioDIGS_dataset” and save it in your environment as “dataset_object_name”. The order of these commands might be odd to our eyes, but it makes perfect sense to RStudio! The soil testing data is called BioDIGS_soil_data in the BioDIGSData package. When we save this dataset into our environment, we’re calling is soil.values. library(BioDIGSData) soil.values &lt;- BioDIGS_soil_data() It seems like the dataset loaded, but it’s always a good idea to verify. There are many ways to check, but the easiest approach (if you’re using RStudio) is to look at the Environment tab on the upper right-hand side of the screen. You should now have an object called soil.values that includes some number of observations for 28 variables. The observations refer to the number of rows in the dataset, while the variables tell you the number of columns. As long as neither the observations or variables are 0, you can be confident that your dataset loaded. Let’s take a quick look at the dataset. We can do this by clicking on soil.values object in the Environment tab. (Note: this is equivalent to typing View(soil.values) in the R console.) This will open a new window for us to scroll through the dataset. Well, the data definitely loaded, but those column names aren’t immediately understandable. What could As_EPA3051 possibly mean? In addition to the dataset, we need to load the data dictionary as well. Data dictionary: a file containing the names, definitions, and attributes about data in a database or dataset. In this case, the data dictionary can help us make sense of what sort of values each column represents. The data dictionary for the BioDIGS soil testing data is available in the R package (see code below), but we have also reproduced it here. ?BioDIGS_soil_data() collection_date: Date sample was collected (soil was removed from a site). site_id: Unique letter and number site name. Check BioDIGS_metadata() for GPS coordinates, origin, and more. sample_id: Unique sequencing sample identifier. site_name_rep_detail: Detailed label for the sample, intended to help disambiguate in case of confusion. As_EPA3051: Arsenic (mg/kg), EPA Method 3051A. Quantities &lt; 3.0 are not detectable. Cd_EPA3051: Cadmium (mg/kg), EPA Method 3051A. Quantities &lt; 0.2 are not detectable. Cr_EPA3051: Chromium (mg/kg), EPA Method 3051A Cu_EPA3051: Copper (mg/kg), EPA Method 3051A Ni_EPA3051: Nickel (mg/kg), EPA Method 3051A Pb_EPA3051: Lead (mg/kg), EPA Method 3051A Zn_EPA3051: Zinc (mg/kg), EPA Method 3051A water_pH: Water pH OM_by_LOI_pct: Organic Matter by Loss on Ignition P_Mehlich3: Phosphorus (mg/kg), using the Mehlich 3 soil test extractant K_Mehlich3: Potassium (mg/kg), using the Mehlich 3 soil test extractant Ca_Mehlich3: Calcium (mg/kg), using the Mehlich 3 soil test extractant Mg_Mehlich3: Magnesium (mg/kg), using the Mehlich 3 soil test extractant Mn_Mehlich3: Manganese (mg/kg), using the Mehlich 3 soil test extractant Zn_Mehlich3: Zinc (mg/kg), using the Mehlich 3 soil test extractant Cu_Mehlich3: Copper (mg/kg), using the Mehlich 3 soil test extractant Fe_Mehlich3: Iron (mg/kg), using the Mehlich 3 soil test extractant B_Mehlich3: Boron (mg/kg), using the Mehlich 3 soil test extractant S_Mehlich3: Sulfur (mg/kg), using the Mehlich 3 soil test extractant Na_Mehlich3: Sodium (mg/kg), using the Mehlich 3 soil test extractant Al_Mehlich3: Aluminum (mg/kg), using the Mehlich 3 soil test extractant Est_CEC: Cation Exchange Capacity (meq/100g) at pH 7.0 (CEC) Base_Sat_pct: Base saturation (BS). This represents the percentage of CEC occupied by bases (Ca2+, Mg2+, K+, and Na+). The %BS increases with increasing soil pH (Figure 5). The availability of Ca2+, Mg2+, and K+ increases with increasing %BS. P_Sat_ratio: Phosphorus saturation ratio. This is the ratio between the amount of phosphorus present in the soil and the total capacity of that soil to retain phosphorus. The ability of phosphorus to be bound in the soil is primary a function of iron (Fe) and aluminum (Al) content in that soil. Using the data dictionary, we find that the values in column As_EPA3051 give us the arsenic concentration in mg/kg of each soil sample, as determined by EPA Method 3051A. This method uses a combination of heat and acid to extract specific elements (like arsenic, cadmium, chromium, copper, nickel, lead, and zinc) from soil samples. While arsenic can occur naturally in soils, higher levels suggest the soil may have been contaminated by mining, hazardous waste, or pesticide application. Arsenic is toxic to humans. QUESTIONS: What data is found in the column labeled “Fe_Mehlich3”? Why would we be interested how much of this is in the soil? (You may have to search the internet for this answer.) What data is found in the column labeled “Base_Sat_pct”? What does this variable tell us about the soil? You may notice that some cells in the soil.values table contain NA. This just means that the soil testing data for that sample isn’t available yet. We’ll take care of those values in the next part. QUESTIONS: How many observations are in the soil testing values dataset that you loaded? What do each of these observations refer to? How many different soil characteristics are in the dataset? How can you tell? "],["part-2.-summarizing-with-statistics.html", "Chapter 11 Part 2. Summarizing with Statistics", " Chapter 11 Part 2. Summarizing with Statistics Now that we have the dataset loaded, let’s explore the data in more depth. First, we should remove those samples that don’t have soil testing data yet. We could keep them in the dataset, but removing them at this stage will make the analysis a little cleaner. In this case, as we know the reason the data are missing (and that reason will not skew our analysis), we can safely remove these samples. This will not be the case for every data analysis. We can remove the unanalyzed samples using the drop_na() function from the tidyverse package. The tidyverse package is a collection of code that makes organizing data tables (also known as data wrangling) easy in R. The drop_na function removes any rows from a table that contains NA for a particular column. This command follows the code structure: dataset_new_name &lt;- dataset_object_name %&gt;% drop_na(column_name) The %&gt;% is called a pipe and it tells R that the commands after it should all be applied to the object in front of it. (In this case, we can filter out all samples missing a value for “As_EPA3051” as a proxy for samples without soil testing data.) The following code block opens the tidyverse package, then tells R to filter out all samples missing a value for “As_EPA3051” (as a proxy for samples without soil testing data) from the soil.values object, and finally to save the new, filtered dataset as an object called soil.values.clean. #install.packages(&#39;tidyverse&#39;) if you haven&#39;t already installed the tidyverse! library(tidyverse) soil.values.clean &lt;- soil.values %&gt;% drop_na(As_EPA3051) Great! Now let’s calculate some basic statistics. For example, we might want to know what the mean (average) arsenic concentration is for all the soil samples. We can use a combination of two functions: pull() and mean(). pull() lets you extract a column from your table for statistical analysis, while mean() calculates the average value for the extracted column. This command follows the code structure: object_name %&gt;% pull(column_name) %&gt;% mean() For this chunk of code, R will calculate the mean for the AS_EPA3051 values in the soil.values.clean dataset. Because we have not used the &lt;- to save the mean in a new object, R will simply display the mean. soil.values.clean %&gt;% pull(As_EPA3051) %&gt;% mean() ## [1] 5.10875 We can run similar commands to calculate the standard deviation (sd), minimum (min), and maximum (max) for the soil arsenic values. soil.values.clean %&gt;% pull(As_EPA3051) %&gt;% sd() ## [1] 5.606926 soil.values.clean %&gt;% pull(As_EPA3051) %&gt;% min() ## [1] 0 soil.values.clean %&gt;% pull(As_EPA3051) %&gt;% max() ## [1] 27.3 The soil testing dataset contains samples from multiple geographic regions, so maybe it’s more meaningful to find out what the average arsenic values are for each region. However, first we need to grab a new dataset from the BioDIGSData package that tells us the geographic regions of each sample. Let’s open BioDIGS_metadata, save it as soil.meta, and look at it. soil.meta &lt;- BioDIGS_metadata() View(soil.meta) The metadata (or, data about the samples) contains information stored as 7 different variables. We can see that this dataset contains a variable called site_id that matches a column in the soil.values and soil.values.clean datasets. This is important! Using this variable, we can combine the soil.values.clean and soil.meta into a single dataset. The command for combining the datasets follows the code structure: combined_dataset_name &lt;- first_dataset %&gt;% inner_join(second_dataset, by = column_name_in_common) The inner_join command tells R to combine the first_dataset and the second_dataset based on matching information in the column_name_in_column. It also only keeps those rows that are found in both datasets. Finally, the &lt;- tells R to save this combined dataset as a new object. soil.combined &lt;- soil.values.clean %&gt;% inner_join(soil.meta, by = &quot;site_id&quot;) View(soil.combined) When you scroll through the soil.combined dataset, you now see the metadata columns after all the soil characteristics. In particular, there’s a column called origin which gives the town or city location for each sample. Many of the samples from the pilot study came from 5 places in Maryland: Baltimore, Derwood, Boyds, Germantown, and Bethesda. Let’s look at the average arsenic content of the soil for each of these locations! We have to do a little bit of clever coding trickery for this using the group_by and summarize functions. First, we tell R to split our dataset up by a particular column (in this case, origin) using the group_by function, then we tell R to summarize the mean arsenic concentration for each group. When using the summarize function, we tell R to make a new table (technically, a tibble in R) that contains two columns: the column used to group the data and the statistical measure we calculated for each group. This command follows the code structure: dataset %&gt;% group_by(column_name) %&gt;% summarize(mean(column_name)) soil.combined %&gt;% group_by(origin) %&gt;% summarize(mean(As_EPA3051)) ## # A tibble: 5 × 2 ## origin `mean(As_EPA3051)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Baltimore, MD 5.56 ## 2 Bethesda, MD 3.46 ## 3 Boyds, MD 6.94 ## 4 Derwood, MD 4.26 ## 5 Germantown, MD 4.30 Now we know that the mean arsenic concentration might be different for each region of origin. QUESTIONS: All the samples in the initial pilot study were collected from public park land. Some parks were located in suburban and rural areas, while others were collected from urban parks. Why might soil arsenic concentration be different for rural parks than for urban parks? What is the mean iron concentration for samples in this dataset? What about the standard deviation, minimum value, and maximum value? Calculate the mean iron concentration by region of origin. Which region has the highest mean iron concentration? What about the lowest? Let’s say we’re interested in looking at mean concentration for any element that was determined using EPA Method 3051. Given that there are 8 of these measures in the soil.combined dataset, it would be time consuming to run our code from above that calculates overall mean for each individual measure. We can add two arguments to our summarize statement to calculate statistical measures for multiple columns at once: the across argument, which tells R to apply the summarize command to multiple columns; and the ends_with parameter, which tells R which columns should be included in the statistical calculation. We are using ends_with because for this question, all the columns that we’re interested in end with the string ‘EPA3051’. This command follows the code structure: dataset %&gt;% group_by(column_name) %&gt;% summarize(across(ends_with(common_column_name_ending), mean)) soil.combined %&gt;% group_by(origin) %&gt;% summarize(across(ends_with(&#39;EPA3051&#39;), mean)) ## # A tibble: 5 × 8 ## origin As_EPA3051 Cd_EPA3051 Cr_EPA3051 Cu_EPA3051 Ni_EPA3051 Pb_EPA3051 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Baltimore, … 5.56 0.359 34.5 35.0 17.4 67.2 ## 2 Bethesda, MD 3.46 0.375 67.5 17.0 26.6 41.8 ## 3 Boyds, MD 6.94 0.0525 16.8 16.8 12.9 31.6 ## 4 Derwood, MD 4.26 0.335 39.5 31.3 35.1 42.1 ## 5 Germantown,… 4.30 0.602 19.9 23.3 17.7 38.2 ## # ℹ 1 more variable: Zn_EPA3051 &lt;dbl&gt; This is a much more efficient way to calculate statistics. QUESTIONS: Calculate the maximum values for concentrations that were determined using EPA Method 3051. (HINT: change the function you call in the summarize statement.) Which of these metals has the maximum concentration you see, and in which region is it found? Calculate both the mean and maximum values for concentrations that were determined using the Mehlich3 test. (HINT: change the terms in the the part of the code that uses ends_with, as well as the function you call in the summarize statement.) Which of these metals has the highest average and maximum concentrations, and in which region are they found? "],["part-3.-visualizing-the-data.html", "Chapter 12 Part 3. Visualizing the Data", " Chapter 12 Part 3. Visualizing the Data Often, it can be easier to immediately interpret data displayed as a plot than as a list of values. For example, we can more easily understand how the arsenic concentration of the soil samples are distributed if we create histograms compared to looking at point values like mean, standard deviation, minimum, and maximum. One way to make histograms in R is with the hist() function. This function only requires that we tell R which column of the dataset that we want to plot. (However, we also have the option to tell R a histogram name and a x-axis label.) We can again use the pull() command and pipes (%&gt;%) to choose the column we want from the soil.values.clean dataset and make a histogram of them. This combination of commands follows the code structure: dataset %&gt;% pull(column_name) %&gt;% hist(main = chart_title, xlab = x_axis_title) soil.combined %&gt;% pull(As_EPA3051) %&gt;% hist(main = &#39;Histogram of Arsenic Concentration&#39;, xlab =&#39;Concentration in mg/kg&#39; ) We can see that almost all the soil samples had very low concentrations of arsenic (which is good news for the soil health!). In fact, many of them had arsenic concentrations close to 0, and only a few sampling locations appear to have high levels of arsenic. We might also want to graphically compare arsenic concentrations among the geographic regions in our dataset. We can do this by creating boxplots. Boxplots are particularly useful when comparing the mean, variation, and distributions among multiple groups. In R, one way to create a boxplot is using the boxplot() function. We don’t need to use pipes for this command, but instead will specify what columns we want to use from the dataset inside the boxplot() function itself. This command follows the code structure: boxplot(column_we’re_plotting ~ grouping_variable, data = dataset, main = “Title of Graph”, xlab = “x_axis_title”, ylab = “y_axis_title”) boxplot(As_EPA3051 ~ origin, data = soil.combined, main = &quot;Arsenic Concentration by Geographic Region&quot;, xlab = &quot;Region&quot;, ylab = &quot;Arsenic Concentration in mg/kg&quot;) By using a boxplot, we can quickly see that, while two sampling sites within Baltimore, MD have a very high concentration of arsenic in the soil (indicated by the two small circles on the plot), in general there isn’t a difference in arsenic content between any of our locations. QUESTIONS: Create a histogram for iron concentration, as well as a boxplot comparing iron concentration by region. Is the iron concentration similar among regions? Are there any outlier sites with unusually high or low iron concentrations? Create a histogram for lead concentration, as well as a boxplot comparing lead concentration by region. Is the lead concentration similar among regions? Are there any outlier sites with unusually high or low lead concentrations? "],["activity-questions.html", "Chapter 13 Activity Questions 13.1 Part 1. Examining the Data 13.2 Part 2. Summarizing the Data with Statistics 13.3 Part 3. Visualizing the Data", " Chapter 13 Activity Questions 13.1 Part 1. Examining the Data What data is found in the column labeled “Fe_Mehlich3”? Why would we be interested how much of this is in the soil? (You may have to search the internet for this answer.) What data is found in the column labeled “Base_Sat_pct”? What does this variable tell us about the soil? How many observations are in the soil testing values dataset that you loaded? What do each of these observations refer to? How many different soil characteristics are in the dataset? How can you tell? 13.2 Part 2. Summarizing the Data with Statistics All the samples in the initial pilot study were collected from public park land. Some parks were located in suburban and rural areas, while others were collected from urban parks. Why might soil arsenic concentration be different for rural parks than for urban parks? What is the mean iron concentration for samples in this dataset? What about the standard deviation, minimum value, and maximum value? Calculate the mean iron concentration by region. Which region has the highest mean iron concentration? What about the lowest? Calculate the maximum values for concentrations that were determined using EPA Method 3051. (HINT: change the function you call in the summarize statement.) Which of these metals has the maximum concentration you see, and in which region is it found? Calculate both the mean and maximum values for concentrations that were determined using the Mehlich3 test. (HINT: change the terms in the columns_to_include vector, as well as the function you call in the summarize statement.) Which of these metals has the highest average and maximum concentrations, and in which region are they found? 13.3 Part 3. Visualizing the Data Create a histogram for iron concentration, as well as a boxplot comparing iron concentration by region. Is the iron concentration similar among regions? Are there any outlier sites with unusually high or low iron concentrations? Create a histogram for lead concentration, as well as a boxplot comparing lead concentration by region. Is the lead concentration similar among regions? Are there any outlier sites with unusually high or low lead concentrations? "],["about-the-authors.html", "About the Authors", " About the Authors These credits are based on our course contributors table guidelines.     Credits Names Pedagogy Content Developer Elizabeth Humphries Content Editors Ava Hoffman, Kate Isaac Project Directors Ava Hoffman, Michael Schatz, Jeff Leek, Frederick Tan Production Content Publisher Ira Gooding Technical Template Publishing Engineers Candace Savonen, Carrie Wright, Ava Hoffman Publishing Maintenance Engineer Candace Savonen Technical Publishing Stylists Carrie Wright, Candace Savonen Package Developers (ottrpal) John Muschelli, Candace Savonen, Carrie Wright Package Developer (BioDIGSData) Ava Hoffman Funding Funder National Human Genome Research Institute (NHGRI) Funding Staff Fallon Bachman, Jennifer Vessio, Emily Voeglein   ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.3.2 (2023-10-31) ## os Ubuntu 22.04.4 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Etc/UTC ## date 2025-02-24 ## pandoc 3.1.1 @ /usr/local/bin/ (via rmarkdown) ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## bookdown 0.41 2024-10-16 [1] CRAN (R 4.3.2) ## bslib 0.6.1 2023-11-28 [1] RSPM (R 4.3.0) ## cachem 1.0.8 2023-05-01 [1] RSPM (R 4.3.0) ## cli 3.6.2 2023-12-11 [1] RSPM (R 4.3.0) ## devtools 2.4.5 2022-10-11 [1] RSPM (R 4.3.0) ## digest 0.6.34 2024-01-11 [1] RSPM (R 4.3.0) ## ellipsis 0.3.2 2021-04-29 [1] RSPM (R 4.3.0) ## evaluate 0.23 2023-11-01 [1] RSPM (R 4.3.0) ## fastmap 1.1.1 2023-02-24 [1] RSPM (R 4.3.0) ## fs 1.6.3 2023-07-20 [1] RSPM (R 4.3.0) ## glue 1.7.0 2024-01-09 [1] RSPM (R 4.3.0) ## htmltools 0.5.7 2023-11-03 [1] RSPM (R 4.3.0) ## htmlwidgets 1.6.4 2023-12-06 [1] RSPM (R 4.3.0) ## httpuv 1.6.14 2024-01-26 [1] RSPM (R 4.3.0) ## jquerylib 0.1.4 2021-04-26 [1] RSPM (R 4.3.0) ## jsonlite 1.8.8 2023-12-04 [1] RSPM (R 4.3.0) ## knitr 1.48 2024-07-07 [1] CRAN (R 4.3.2) ## later 1.3.2 2023-12-06 [1] RSPM (R 4.3.0) ## lifecycle 1.0.4 2023-11-07 [1] RSPM (R 4.3.0) ## magrittr 2.0.3 2022-03-30 [1] RSPM (R 4.3.0) ## memoise 2.0.1 2021-11-26 [1] RSPM (R 4.3.0) ## mime 0.12 2021-09-28 [1] RSPM (R 4.3.0) ## miniUI 0.1.1.1 2018-05-18 [1] RSPM (R 4.3.0) ## pkgbuild 1.4.3 2023-12-10 [1] RSPM (R 4.3.0) ## pkgload 1.3.4 2024-01-16 [1] RSPM (R 4.3.0) ## profvis 0.3.8 2023-05-02 [1] RSPM (R 4.3.0) ## promises 1.2.1 2023-08-10 [1] RSPM (R 4.3.0) ## purrr 1.0.2 2023-08-10 [1] RSPM (R 4.3.0) ## R6 2.5.1 2021-08-19 [1] RSPM (R 4.3.0) ## Rcpp 1.0.12 2024-01-09 [1] RSPM (R 4.3.0) ## remotes 2.4.2.1 2023-07-18 [1] RSPM (R 4.3.0) ## rlang 1.1.4 2024-06-04 [1] CRAN (R 4.3.2) ## rmarkdown 2.25 2023-09-18 [1] RSPM (R 4.3.0) ## sass 0.4.8 2023-12-06 [1] RSPM (R 4.3.0) ## sessioninfo 1.2.2 2021-12-06 [1] RSPM (R 4.3.0) ## shiny 1.8.0 2023-11-17 [1] RSPM (R 4.3.0) ## stringi 1.8.3 2023-12-11 [1] RSPM (R 4.3.0) ## stringr 1.5.1 2023-11-14 [1] RSPM (R 4.3.0) ## urlchecker 1.0.1 2021-11-30 [1] RSPM (R 4.3.0) ## usethis 2.2.3 2024-02-19 [1] RSPM (R 4.3.0) ## vctrs 0.6.5 2023-12-01 [1] RSPM (R 4.3.0) ## xfun 0.48 2024-10-03 [1] CRAN (R 4.3.2) ## xtable 1.8-4 2019-04-21 [1] RSPM (R 4.3.0) ## yaml 2.3.8 2023-12-11 [1] RSPM (R 4.3.0) ## ## [1] /usr/local/lib/R/site-library ## [2] /usr/local/lib/R/library ## ## ────────────────────────────────────────────────────────────────────────────── "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
